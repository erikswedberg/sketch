diff --git a/llm/ant/ant.go b/llm/ant/ant.go
index 2cc7a55..2052f2e 100644
--- a/llm/ant/ant.go
+++ b/llm/ant/ant.go
@@ -11,6 +11,7 @@ import (
 	"log/slog"
 	"math/rand/v2"
 	"net/http"
+	"os"
 	"strings"
 	"testing"
 	"time"
@@ -25,6 +26,7 @@ const (
 	DefaultMaxTokens = 8192
 	APIKeyEnv        = "ANTHROPIC_API_KEY"
 	DefaultURL       = "https://api.anthropic.com/v1/messages"
+	toolPrefix       = "sk_" // prefix for tool names when using OAuth tokens
 )
 
 const (
@@ -84,6 +86,12 @@ type Service struct {
 	Model     string       // defaults to DefaultModel if empty
 	MaxTokens int          // defaults to DefaultMaxTokens if zero
 	DumpLLM   bool         // whether to dump request/response text to files for debugging; defaults to false
+	isProMode bool         // internal flag set when using Claude Pro/Max OAuth tokens
+}
+
+// isClaudeProToken reports whether apiKey is a Claude Pro/Max OAuth token.
+func isClaudeProToken(apiKey string) bool {
+	return strings.HasPrefix(apiKey, "sk-ant-oat")
 }
 
 var _ llm.Service = (*Service)(nil)
@@ -365,6 +373,20 @@ func fromLLMTool(t *llm.Tool) *tool {
 	}
 }
 
+// fromLLMToolWithPrefix converts an llm.Tool to an Anthropic tool, optionally prefixing the name
+func fromLLMToolWithPrefix(t *llm.Tool, prefix string) *tool {
+	name := t.Name
+	if prefix != "" {
+		name = prefix + name
+	}
+	return &tool{
+		Name:        name,
+		Type:        t.Type,
+		Description: t.Description,
+		InputSchema: t.InputSchema,
+	}
+}
+
 func fromLLMSystem(s llm.SystemContent) systemContent {
 	return systemContent{
 		Text:         s.Text,
@@ -374,13 +396,47 @@ func fromLLMSystem(s llm.SystemContent) systemContent {
 }
 
 func (s *Service) fromLLMRequest(r *llm.Request) *request {
+	// Determine model based on mode
+	model := cmp.Or(s.Model, DefaultModel)
+	if s.isProMode {
+		// In Pro mode, support Sonnet or Opus
+		if strings.Contains(model, "opus") {
+			model = Claude45Opus
+		} else {
+			model = Claude45Sonnet
+		}
+	}
+
+	// Build system messages
+	var system []systemContent
+	if s.isProMode {
+		// Prepend Claude Code system prompt for Pro/Max mode
+		system = append(system, systemContent{
+			Text: "You are Claude Code, Anthropic's official CLI for Claude.",
+			Type: "text",
+		})
+	}
+	// Append user's system messages
+	system = append(system, mapped(r.System, fromLLMSystem)...)
+
+	// Convert tools, with prefixing for Pro mode
+	var tools []*tool
+	if s.isProMode {
+		tools = make([]*tool, len(r.Tools))
+		for i, t := range r.Tools {
+			tools[i] = fromLLMToolWithPrefix(t, toolPrefix)
+		}
+	} else {
+		tools = mapped(r.Tools, fromLLMTool)
+	}
+
 	return &request{
-		Model:      cmp.Or(s.Model, DefaultModel),
+		Model:      model,
 		Messages:   mapped(r.Messages, fromLLMMessage),
 		MaxTokens:  cmp.Or(s.MaxTokens, DefaultMaxTokens),
 		ToolChoice: fromLLMToolChoice(r.ToolChoice),
-		Tools:      mapped(r.Tools, fromLLMTool),
-		System:     mapped(r.System, fromLLMSystem),
+		Tools:      tools,
+		System:     system,
 	}
 }
 
@@ -436,8 +492,34 @@ func toLLMResponse(r *response) *llm.Response {
 	}
 }
 
+// unprefixToolNames removes the tool prefix from tool names in response content
+func unprefixToolNames(contents []llm.Content, prefix string) []llm.Content {
+	if prefix == "" {
+		return contents
+	}
+	for i := range contents {
+		if contents[i].ToolName != "" && strings.HasPrefix(contents[i].ToolName, prefix) {
+			contents[i].ToolName = strings.TrimPrefix(contents[i].ToolName, prefix)
+		}
+	}
+	return contents
+}
+
 // Do sends a request to Anthropic.
 func (s *Service) Do(ctx context.Context, ir *llm.Request) (*llm.Response, error) {
+	// Read API key from file if it's a file path, otherwise use as-is
+	apiKey := s.APIKey
+	if _, err := os.Stat(apiKey); err == nil {
+		keyBytes, err := os.ReadFile(apiKey)
+		if err != nil {
+			return nil, fmt.Errorf("failed to read API key from file %s: %w", apiKey, err)
+		}
+		apiKey = strings.TrimSpace(string(keyBytes))
+	}
+
+	// Detect Claude Pro/Max mode based on API key
+	s.isProMode = isClaudeProToken(apiKey)
+
 	request := s.fromLLMRequest(ir)
 
 	var payload []byte
@@ -474,30 +556,66 @@ func (s *Service) Do(ctx context.Context, ir *llm.Request) (*llm.Response, error
 			slog.WarnContext(ctx, "anthropic request sleep before retry", "sleep", sleep, "attempts", attempts)
 			time.Sleep(sleep)
 		}
-		if s.DumpLLM {
-			if err := llm.DumpToFile("request", url, payload); err != nil {
-				slog.WarnContext(ctx, "failed to dump request to file", "error", err)
-			}
-		}
 		req, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewReader(payload))
 		if err != nil {
 			return nil, errors.Join(errs, err)
 		}
 
 		req.Header.Set("Content-Type", "application/json")
-		req.Header.Set("X-API-Key", s.APIKey)
 		req.Header.Set("Anthropic-Version", "2023-06-01")
 
-		var features []string
-		if request.TokenEfficientToolUse {
-			features = append(features, "token-efficient-tool-use-2025-02-19")
+		// Set authentication header based on mode
+		if s.isProMode {
+			req.Header.Set("Authorization", "Bearer "+apiKey)
+		} else {
+			req.Header.Set("X-API-Key", apiKey)
 		}
-		if largerMaxTokens {
-			features = append(features, "output-128k-2025-02-19")
-			request.MaxTokens = 128 * 1024
+
+		// Set anthropic-beta header
+		if s.isProMode {
+			// Claude Pro/Max mode requires specific beta features
+			req.Header.Set("anthropic-beta", "oauth-2025-04-20,claude-code-20250219,interleaved-thinking-2025-05-14,fine-grained-tool-streaming-2025-05-14")
+		} else {
+			// Normal API key mode - conditionally set beta features
+			var features []string
+			if request.TokenEfficientToolUse {
+				features = append(features, "token-efficient-tool-use-2025-02-19")
+			}
+			if largerMaxTokens {
+				features = append(features, "output-128k-2025-02-19")
+				request.MaxTokens = 128 * 1024
+			}
+			if len(features) > 0 {
+				req.Header.Set("anthropic-beta", strings.Join(features, ","))
+			}
 		}
-		if len(features) > 0 {
-			req.Header.Set("anthropic-beta", strings.Join(features, ","))
+
+		// Dump full request metadata for debugging
+		if s.DumpLLM {
+			var dumpData strings.Builder
+			fmt.Fprintf(&dumpData, "=== REQUEST METADATA ===\n")
+			fmt.Fprintf(&dumpData, "URL: %s\n", url)
+			fmt.Fprintf(&dumpData, "Method: POST\n")
+			fmt.Fprintf(&dumpData, "Headers:\n")
+			for k, v := range req.Header {
+				if k == "Authorization" || k == "X-API-Key" {
+					fmt.Fprintf(&dumpData, "  %s: [REDACTED]\n", k)
+				} else {
+					fmt.Fprintf(&dumpData, "  %s: %s\n", k, strings.Join(v, ", "))
+				}
+			}
+			fmt.Fprintf(&dumpData, "\nPro Mode: %v\n", s.isProMode)
+			fmt.Fprintf(&dumpData, "Model (Service): %s\n", s.Model)
+			fmt.Fprintf(&dumpData, "Model (Request): %s\n", request.Model)
+			fmt.Fprintf(&dumpData, "System Messages: %d\n", len(request.System))
+			if len(request.System) > 0 {
+				fmt.Fprintf(&dumpData, "First System Message: %s\n", request.System[0].Text)
+			}
+			fmt.Fprintf(&dumpData, "\n=== REQUEST PAYLOAD ===\n")
+			dumpData.Write(payload)
+			if err := llm.DumpToFile("request", url, []byte(dumpData.String())); err != nil {
+				slog.WarnContext(ctx, "failed to dump request to file", "error", err)
+			}
 		}
 
 		resp, err := httpc.Do(req)
@@ -543,19 +661,33 @@ func (s *Service) Do(ctx context.Context, ir *llm.Request) (*llm.Response, error
 			}
 			response.Usage.CostUSD = llm.CostUSDFromResponse(resp.Header)
 
-			return toLLMResponse(&response), nil
+			llmResp := toLLMResponse(&response)
+			// Unprefix tool names if in Pro mode
+			if s.isProMode {
+				llmResp.Content = unprefixToolNames(llmResp.Content, toolPrefix)
+			}
+			return llmResp, nil
 		case resp.StatusCode >= 500 && resp.StatusCode < 600:
 			// server error, retry
 			slog.WarnContext(ctx, "anthropic_request_failed", "response", string(buf), "status_code", resp.StatusCode)
 			errs = errors.Join(errs, fmt.Errorf("status %v: %s", resp.Status, buf))
 			continue
 		case resp.StatusCode == 429:
-			// rate limited, retry
-			slog.WarnContext(ctx, "anthropic_request_rate_limited", "response", string(buf))
+			// rate limited - check if it's quota exhaustion or temporary throttling
+			if attempts >= 2 {
+				// After 2 retries, give up - likely quota exhaustion, not temporary rate limit
+				slog.WarnContext(ctx, "anthropic_request_rate_limited_giving_up", "response", string(buf), "attempts", attempts)
+				return nil, errors.Join(errs, fmt.Errorf("rate limited after %d attempts: %s", attempts, buf))
+			}
+			slog.WarnContext(ctx, "anthropic_request_rate_limited", "response", string(buf), "attempts", attempts)
 			errs = errors.Join(errs, fmt.Errorf("status %v: %s", resp.Status, buf))
 			continue
 		case resp.StatusCode >= 400 && resp.StatusCode < 500:
-			// some other 400, probably unrecoverable
+			// Client error - likely unrecoverable (bad request, auth, not found, etc.)
+			if resp.StatusCode == 401 {
+				slog.WarnContext(ctx, "anthropic_request_unauthorized", "response", string(buf))
+				return nil, fmt.Errorf("unauthorized (expired or invalid token): %s", buf)
+			}
 			slog.WarnContext(ctx, "anthropic_request_failed", "response", string(buf), "status_code", resp.StatusCode)
 			return nil, errors.Join(errs, fmt.Errorf("status %v: %s", resp.Status, buf))
 		default:
diff --git a/loop/agent.go b/loop/agent.go
index 6e72cf8..d832ef1 100644
--- a/loop/agent.go
+++ b/loop/agent.go
@@ -171,6 +171,11 @@ type CodingAgent interface {
 
 	// ExternalMessage enqueues an external message to the agent and returns immediately.
 	ExternalMessage(ctx context.Context, msg ExternalMessage) error
+
+	// PlanMode returns whether plan mode is enabled.
+	PlanMode() bool
+	// SetPlanMode enables or disables plan mode.
+	SetPlanMode(enabled bool)
 }
 
 type CodingAgentMessageType string
@@ -484,6 +489,56 @@ type Agent struct {
 
 	// Track outstanding tool calls by ID with their names
 	outstandingToolCalls map[string]string
+
+	// planMode when true restricts to read-only tools
+	planMode bool
+	// allTools stores the complete tool list for restoring after plan mode
+	allTools []*llm.Tool
+}
+
+// planModeBlockedTools are tools disabled in plan mode
+var planModeBlockedTools = map[string]bool{
+	"patch":      true,
+	"done":       true,
+	"codereview": true,
+}
+
+// PlanMode returns whether plan mode is enabled.
+func (a *Agent) PlanMode() bool {
+	a.mu.Lock()
+	defer a.mu.Unlock()
+	return a.planMode
+}
+
+// SetPlanMode enables or disables plan mode and updates available tools.
+func (a *Agent) SetPlanMode(enabled bool) {
+	a.mu.Lock()
+	defer a.mu.Unlock()
+	a.planMode = enabled
+
+	convo, ok := a.convo.(*conversation.Convo)
+	if !ok {
+		return
+	}
+
+	// Store full tool list on first call
+	if a.allTools == nil {
+		a.allTools = convo.Tools
+	}
+
+	if enabled {
+		// Filter to read-only tools
+		var filtered []*llm.Tool
+		for _, t := range a.allTools {
+			if !planModeBlockedTools[t.Name] {
+				filtered = append(filtered, t)
+			}
+		}
+		convo.Tools = filtered
+	} else {
+		// Restore all tools
+		convo.Tools = a.allTools
+	}
 }
 
 // ExternalMessage implements CodingAgent.
@@ -1831,6 +1886,11 @@ func (a *Agent) processUserMessage(ctx context.Context) (*llm.Response, error) {
 		})
 	}
 
+	// Append plan mode indicator if enabled
+	if a.PlanMode() {
+		msgs = append(msgs, llm.StringContent("\n[PLAN MODE]"))
+	}
+
 	userMessage := llm.Message{
 		Role:    llm.MessageRoleUser,
 		Content: msgs,
diff --git a/loop/agent_system_prompt.txt b/loop/agent_system_prompt.txt
index 3388cb3..38465a2 100644
--- a/loop/agent_system_prompt.txt
+++ b/loop/agent_system_prompt.txt
@@ -1,6 +1,12 @@
 You are the expert software engineer and architect powering Sketch,
 an agentic coding environment that helps users accomplish coding tasks through autonomous analysis and implementation.
 
+You operate in one of two modes:
+- BUILD MODE (default): All tools available. Make changes, write code, commit.
+- PLAN MODE: Editing tools are disabled. Research, analyze, read, discuss, plan only.
+
+If a message ends with "[PLAN MODE]" you are in plan mode.
+
 {{- if .SpecialInstruction }}
 {{ .SpecialInstruction }}
 
diff --git a/loop/server/loophttp.go b/loop/server/loophttp.go
index 4738a70..5ea0207 100644
--- a/loop/server/loophttp.go
+++ b/loop/server/loophttp.go
@@ -175,6 +175,7 @@ type State struct {
 	SessionEnded         bool                          `json:"session_ended,omitempty"`
 	CanSendMessages      bool                          `json:"can_send_messages,omitempty"`
 	EndedAt              time.Time                     `json:"ended_at,omitempty"`
+	PlanMode             bool                          `json:"plan_mode"`
 }
 
 // Port represents an open TCP port
@@ -797,6 +798,28 @@ func New(agent loop.CodingAgent, logFile *os.File) (*Server, error) {
 	// Handler for /git/push - handles git push operations
 	s.mux.HandleFunc("/git/push", s.handleGitPush)
 
+	// Handler for /plan-mode - get or set plan mode
+	s.mux.HandleFunc("/plan-mode", func(w http.ResponseWriter, r *http.Request) {
+		switch r.Method {
+		case http.MethodGet:
+			w.Header().Set("Content-Type", "application/json")
+			json.NewEncoder(w).Encode(map[string]bool{"plan_mode": agent.PlanMode()})
+		case http.MethodPost:
+			var body struct {
+				Enabled bool `json:"enabled"`
+			}
+			if err := json.NewDecoder(r.Body).Decode(&body); err != nil {
+				httpError(w, r, "Invalid request body", http.StatusBadRequest)
+				return
+			}
+			agent.SetPlanMode(body.Enabled)
+			w.Header().Set("Content-Type", "application/json")
+			json.NewEncoder(w).Encode(map[string]bool{"plan_mode": agent.PlanMode()})
+		default:
+			httpError(w, r, "Method not allowed", http.StatusMethodNotAllowed)
+		}
+	})
+
 	// Handler for /cancel - cancels the current inner loop in progress
 	s.mux.HandleFunc("/cancel", func(w http.ResponseWriter, r *http.Request) {
 		if r.Method != http.MethodPost {
@@ -1584,6 +1607,7 @@ func (s *Server) getState() State {
 		OpenPorts:            s.getOpenPorts(),
 		TokenContextWindow:   s.agent.TokenContextWindow(),
 		Model:                s.agent.ModelName(),
+		PlanMode:             s.agent.PlanMode(),
 	}
 }
 
diff --git a/webui/src/data.ts b/webui/src/data.ts
index 749b095..8576558 100644
--- a/webui/src/data.ts
+++ b/webui/src/data.ts
@@ -533,6 +533,32 @@ export class DataManager {
     window.location.href = "download";
   }
 
+  /**
+   * Get plan mode state
+   */
+  public getPlanMode(): boolean {
+    return this.timelineState?.plan_mode ?? false;
+  }
+
+  /**
+   * Set plan mode
+   */
+  public async setPlanMode(enabled: boolean): Promise<boolean> {
+    try {
+      const response = await fetch("plan-mode", {
+        method: "POST",
+        headers: { "Content-Type": "application/json" },
+        body: JSON.stringify({ enabled }),
+      });
+      if (!response.ok) return false;
+      const data = await response.json();
+      return data.plan_mode;
+    } catch (error) {
+      console.error("Error setting plan mode:", error);
+      return false;
+    }
+  }
+
   /**
    * Get a suggested reprompt
    */
diff --git a/webui/src/fixtures/dummy.ts b/webui/src/fixtures/dummy.ts
index f3b4f1b..a0a4f9e 100644
--- a/webui/src/fixtures/dummy.ts
+++ b/webui/src/fixtures/dummy.ts
@@ -572,6 +572,7 @@ export const initialState: State = {
   agent_state: "WaitingForUserInput",
   diff_lines_added: 42,
   diff_lines_removed: 7,
+  plan_mode: false,
   open_ports: [
     {
       port: 3000,
diff --git a/webui/src/types.ts b/webui/src/types.ts
index d0ed5de..638e640 100644
--- a/webui/src/types.ts
+++ b/webui/src/types.ts
@@ -115,6 +115,7 @@ export interface State {
 	session_ended?: boolean;
 	can_send_messages?: boolean;
 	ended_at?: string;
+	plan_mode: boolean;
 }
 
 export interface TodoItem {
diff --git a/webui/src/web-components/demo/demo-fixtures/container-status.ts b/webui/src/web-components/demo/demo-fixtures/container-status.ts
index 9e763f6..1e578e5 100644
--- a/webui/src/web-components/demo/demo-fixtures/container-status.ts
+++ b/webui/src/web-components/demo/demo-fixtures/container-status.ts
@@ -52,6 +52,7 @@ export const sampleContainerState: State = {
   ssh_connection_string: "ssh user@example.com",
   diff_lines_added: 245,
   diff_lines_removed: 67,
+  plan_mode: false,
 };
 
 export const lightUsageState: State = {
diff --git a/webui/src/web-components/sketch-app-shell-base.ts b/webui/src/web-components/sketch-app-shell-base.ts
index 2f425a0..fd2a66d 100644
--- a/webui/src/web-components/sketch-app-shell-base.ts
+++ b/webui/src/web-components/sketch-app-shell-base.ts
@@ -91,6 +91,10 @@ export abstract class SketchAppShellBase extends SketchTailwindElement {
   @state()
   protected _todoPanelVisible: boolean = false;
 
+  // Track plan mode state
+  @state()
+  planMode: boolean = false;
+
   // Store scroll position for the chat view to preserve it when switching tabs
   @state()
   private _chatScrollPosition: number = 0;
@@ -140,6 +144,7 @@ export abstract class SketchAppShellBase extends SketchTailwindElement {
     first_message_index: 0,
     diff_lines_added: 0,
     diff_lines_removed: 0,
+    plan_mode: false,
   };
 
   // Mutation observer to detect when new messages are added
@@ -605,6 +610,7 @@ export abstract class SketchAppShellBase extends SketchTailwindElement {
 
       this.containerState = state;
       this.slug = state.slug || "";
+      this.planMode = state.plan_mode || false;
 
       // Update document title when sketch slug changes
       this.updateDocumentTitle();
@@ -777,6 +783,11 @@ export abstract class SketchAppShellBase extends SketchTailwindElement {
     }
   }
 
+  async _togglePlanMode() {
+    const newMode = await this.dataManager.setPlanMode(!this.planMode);
+    this.planMode = newMode;
+  }
+
   async _sendChat(e: CustomEvent) {
     console.log("app shell: _sendChat", e);
     e.preventDefault();
@@ -1073,7 +1084,9 @@ export abstract class SketchAppShellBase extends SketchTailwindElement {
       >
         <sketch-chat-input
           @send-chat="${this._sendChat}"
+          @toggle-plan-mode="${this._togglePlanMode}"
           .isDisconnected=${this.connectionStatus === "disconnected"}
+          .planMode=${this.planMode}
         ></sketch-chat-input>
       </div>
     `;
diff --git a/webui/src/web-components/sketch-chat-input.ts b/webui/src/web-components/sketch-chat-input.ts
index 425e4a2..374a094 100644
--- a/webui/src/web-components/sketch-chat-input.ts
+++ b/webui/src/web-components/sketch-chat-input.ts
@@ -19,6 +19,9 @@ export class SketchChatInput extends SketchTailwindElement {
   @property()
   isDisconnected: boolean = false;
 
+  @property({ type: Boolean })
+  planMode: boolean = false;
+
   constructor() {
     super();
     this._handleDiffComment = this._handleDiffComment.bind(this);
@@ -259,6 +262,15 @@ export class SketchChatInput extends SketchTailwindElement {
     requestAnimationFrame(() => this.adjustChatSpacing());
   }
 
+  _togglePlanMode() {
+    this.dispatchEvent(
+      new CustomEvent("toggle-plan-mode", {
+        bubbles: true,
+        composed: true,
+      })
+    );
+  }
+
   _chatInputKeyDown(event: KeyboardEvent) {
     // Send message if Enter is pressed without Shift key
     if (event.key === "Enter" && !event.shiftKey) {
@@ -340,6 +352,10 @@ export class SketchChatInput extends SketchTailwindElement {
                 ? "Uploading..."
                 : "Send"}
           </button>
+          <span
+            @click="${this._togglePlanMode}"
+            class="font-mono text-xs text-gray-500 dark:text-neutral-400 cursor-pointer hover:underline hover:text-blue-600 dark:hover:text-blue-400 self-center ml-2 select-none"
+          >${this.planMode ? "[PLAN MODE]" : "[BUILD MODE]"}</span>
         </div>
         ${this.isDraggingOver
           ? html`
diff --git a/webui/src/web-components/sketch-container-status.test.ts b/webui/src/web-components/sketch-container-status.test.ts
index 7ef780c..b552bbb 100644
--- a/webui/src/web-components/sketch-container-status.test.ts
+++ b/webui/src/web-components/sketch-container-status.test.ts
@@ -29,6 +29,7 @@ const mockCompleteState: State = {
   first_message_index: 0,
   diff_lines_added: 15,
   diff_lines_removed: 3,
+  plan_mode: false,
 };
 
 test("render props", async ({ mount }) => {
